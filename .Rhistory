ggplot() +
geom_linerange(aes(variable, ymin = `2.5%`,ymax = `97.5%`)) +
geom_crossbar(aes(variable, mean, ymin = `25%`, ymax = `75%`), fill= 'grey') +
facet_wrap(~variable, scales = 'free') +
geom_point(aes(variable, mean_obs), color = "red" ) #observed
colMeans(o_run_comp)
colMeans(p)
D_sum
View(bh_summary_g_all)
D_scale = 0.4411873
pi = c(0.1148158, 0.1909981, 0.4164682, 0.2777180)
D_sum = 1/D_scale^2
rdirichlet(pi,D_sum)
pi
D_sum
pi[1]
nRyrs
rdirichlet(nRyrs, pi[1],D_sum)
rdirichlet(pi[1],D_sum)
rdirichlet(n=nRyrs, pi[1],D_sum)
rdirichlet(n=nRyrs, pi[1])
rdirichlet(n=nRyrs, pi)
theta = rdirichlet(n=nRyrs, pi)
theta
theta = rdirichlet(n=nRyrs, Dir_alpha)
theta
rmultinom(theta, 1)
rmultinom(size =1, prob =  theta)
rmultinom(size =1, n=1, prob =  theta)
rmultinom(size =1, n=1, prob =  theta)
o_run_comp
rmultinom(1,ess_age_comp, start_p_age_comp)
start_p_age_comp = c(0.1148158, 0.1909981, 0.4164682, 0.2777180)
p = rmultinom(1,ess_age_comp, start_p_age_comp)
p
rmultinom(1,1, start_p_age_comp)
p = rmultinom(nRyrs,ess_age_comp, start_p_age_comp)
p
pi = c(0.1148158, 0.1909981, 0.4164682, 0.2777180)
sum(pi)
H_b  <-  array(data = rmultinom(n=nRyrs,size =500, prob = pi),
dim = c(nRyrs, K, A))
H_b
library(actuaryr)
library(readxl)
library(tidyverse)
library(dplyr)
library(rstan)
library(dirmult)
library(here)
library(Rlab)
#### Simulating data
# Load data for baseline ==============
warmups <- 2000
total_iterations <- 4000
max_treedepth <-  15
n_chains <- 1
n_cores <- 4
adapt_delta <- 0.95
# load salmon data ================================================
# summer_age_comp<-read_csv("data/age_comps/processed_age_comps_summer_yukon.csv")  %>%
#   filter(!cal_year < 2005 )
#
# summer_brood <- read_csv("output/yukon_summer_broodyear.csv")%>%
#   filter(!brood_year < 2002) # for now to simplify matching with juveniles
#
# yukon_summer <- read_excel("data/Yukon_Escapement_ADFG/S Chum RR 2023.xlsx", sheet = 2) %>%
#   dplyr::select(1,11:14) %>%
#   janitor::row_to_names(row_number = 1) %>%
#   dplyr::rename(cal_year = "Year")  %>%
#   dplyr::mutate(age3=as.numeric(age3),
#                 age4=as.numeric(age4),
#                 age5=as.numeric(age5),
#                 age6=as.numeric(age6)) %>%
#   filter(!cal_year < 2005)
#
# ## harvest below weir
# harvest_escapement <- read_excel("data/Yukon_Escapement_ADFG/S Chum RR 2023.xlsx", sheet = 2) %>%
#   dplyr::select(1:2,4) %>%
#   janitor::row_to_names(row_number = 1)  %>%
#   dplyr::rename(cal_year = "Year") %>%
#   dplyr::mutate(cal_year = as.numeric(cal_year),
#                 Harvest = as.numeric(Harvest),
#                 Escapement = as.numeric(Escapement)) %>%
#   filter(!cal_year < 2005) %>% # from brood year 2002 (first year of juvenile data), the first year that fish could return is 2005 if its a 3yo, the last yera it coudl return is 2007 if its a 6yo.
#   as.data.frame()  #%>%
# #as.matrix()
#
# # juv data =========
# juv<- read_csv("data/tidy_BASIS_AYK_model.csv") %>%
#   dplyr::select(1,2) %>% # yukon summer is column labeled 1, yukon fall is 2, kusko is 3
#   dplyr::rename(abund = `1`) %>%
#   filter(!brood_year>2017) #if a fish is caught in 2023 and is 6 years old,
# # then its brood  year is 2017. Need to trim so the indexing works... I think...
# Init ===================
nByrs= 80 #105 #number of samples per population
nRyrs = 83 #108
pops = 1 #seq(1,3,1) #population pointer vector
population<- c(rep(1,nByrs)) #population pointer vector
K = 1 # number of stocks
A = 4 # age classes
#n.pop <-length(unique(population)) #number of population
#year <- rep(seq(1,n), n.pop) #creating a year pointer
Ps = 0.5 # proportion of females - assumption, need to lit check
fs = as.matrix(c(1800, 2000, 2200, 2440)) # fecundity - Gilk-Baumer 2009 estimate for Kusko Chum is: 2440. I added extra numbers temporarily just so that younger fish reproduce less, but will have to look up data for this more...
#Bev Holt parameters ===================
# p for alpha, and c for carrying capacity
basal_p_1 = 0.2
basal_p_2 = 0.4
log_c_1 = 18.4
log_c_2 = 15
c_1 <- as.matrix(nrow = 1, ncol =1, exp(log_c_1))
c_2 <- as.matrix(nrow = 1, ncol =1, exp(log_c_2))
# Covariate data ===================
cov1 <-  matrix(nrow = nByrs, ncol =1, rnorm(nByrs*1, 0, 2))  #Cov 1 data
cov2 <- matrix(nrow = nByrs, ncol =1, rnorm(nByrs*1, 0, 2))  #Cov2 data
sigma_coef1 <- as.matrix(nrow = 1, ncol =1, 0.1)
sigma_coef2 <- as.matrix(nrow = 1, ncol =1, 0.1)
mu_coef1 <- 0.1 #rnorm(0, 10)
mu_coef2 <- -0.2 #rnorm(0, 10)
theta1 <- rnorm(1,mu_coef1,sigma_coef1[1,1])
theta2 <- rnorm(1,mu_coef2,sigma_coef2[1,1])
# theta1 <- c(0.1) #rep(0.1,n), rep(0.3,n), rep(0.4,n)) #relationship for simulated data
# theta2 <- c(-0.2) #relationship for simulated data
# Make p for simulated population model =========
#
pi = c(NA)
Dir_alpha = c(NA)
p = matrix(nrow=nRyrs,ncol=A,NA)
g = matrix(nrow=nRyrs,ncol=A,NA)
# prob = c(0.1148158, # rbeta(1,1,1),
#          0.2157721, # rbeta(1,1,1),
#          0.5999373)  # rbeta(1,1,1))
D_scale = 0.4411873 #
# pi[1] = prob[1]
# pi[2] = prob[2] * (1 - pi[1])
# pi[3] = prob[3] * (1 - pi[1] - pi[2])
# pi[4] = 1 - pi[1] - pi[2] - pi[3]
pi = c(0.1148158, 0.1909981, 0.4164682, 0.2777180)
D_sum = 1/D_scale^2
D_sum
for (a in 1:A) {
for (t in 1:nRyrs) {
Dir_alpha[a] = D_sum * pi[a]
g[t,a] = rgamma(n=1,Dir_alpha[a],1)
}
}
Dir_alpha
for (a in 1:A) {
for (t in 1:nRyrs) {
p[t,a] = g[t,a]/sum(g[t,1:A])
}
}
# Process error  ===================
# error is fixed in model right now so fix it here.
process_error_j <- matrix(nrow=K,ncol=1,rep(5, times =K))  #matrix(nrow=nByrs,ncol=1,rep(1, times =nByrs )) #rnorm(nByrs*1,1,0.2))
process_error_sp <- matrix(nrow=K,ncol=1,rep(5, times =K)) #matrix(nrow=nRyrs,ncol=1,rep(2, times =nRyrs )) #rnorm(nByrs*1,5, 1))
process_error_r <- matrix(nrow=K,ncol=1,rep(5, times =K))  #matrix(nrow=nRyrs,ncol=1,rep(3, times =nRyrs )) #rnorm(nByrs*1,5, 1))
# make pop model matricies and starting values =========
kappa_j =  matrix(nrow=nByrs,ncol=K,NA)
kappa_marine =  matrix(nrow=nByrs,ncol=K,NA)
N_j =  matrix(nrow=nByrs,ncol=K,NA)
N_e_sum = matrix(nrow=nByrs,ncol=K,NA)
N_recruit = matrix(nrow=nByrs,ncol=K,NA)
N_e = array(data = NA, dim = c(nRyrs, K,A))
N_returning = array(data = NA, dim = c(nRyrs, K,A))
N_sp = array(data = NA, dim = c(nRyrs, K,A))
## starting values ========
mean.spawn <- exp(rep(c(rnorm(1,14,2), rnorm(1,14,2), rnorm(1,14,2), rnorm(1,14,2)), times=A))
N_sp[1:A,1,] <- mean.spawn
N_e[1,1,] = exp(rnorm(A,20,2))
N_j[1,1] = exp(rnorm(1,20,2)) #mean(juv$abund)# rnorm(K,20,10)
N_recruit[1,1] = exp(rnorm(1,14,2)) #mean(harvest_escapement$Harvest)
N_returning[1:A,1,]  = rep(exp(rnorm(1,15,2))*pi, times =A)
N_e_sum[1,1] = exp(rnorm(1,35,2))
# productivity =============
# p_1 =  matrix(nrow=nByrs,ncol=K,NA)
# p_2 =  matrix(nrow=nByrs,ncol=K,NA)
log_p_1 =  matrix(nrow=1,ncol=K,rnorm(1,-1.6, 0.5))
log_p_2 =  matrix(nrow=1,ncol=K,rnorm(1,-0.9, 0.5))
p_1 = exp(log_p_1)
p_2 = exp(log_p_2)
catch_q = exp(rnorm(1,0,0.5))
# Harvest H_b ==========
# this is the harvest, going to do a percent of the population instead of whole numbers
# simulating with dirichlet leads to age structure being the same across all ages at 0.25
#H_b  <-  array(data = rdirichlet(n=nRyrs, alpha=rep(10,A)), dim = c(nRyrs, K, A)) # higher value for alpha is a more tightly clustered distribution
H_b  <-  array(data = rdirichlet(n=nRyrs, alpha=rep(10,A)), dim = c(nRyrs, K, A)) # higher value for alpha is a more tightly clustered distribution
# Run population model ============
for(k in 1:K){  # loop for each population
for (t in 2:nByrs){ # loop for each brood year
kappa_j[t,k] =  p_1[1,k]/ (1+((p_1[1,k]*N_e_sum[t-1,k])/c_1[k,1])) # Eq 4.1  - Bev holt transition estimating survival from Egg to Juvenile (plugs into Eq 4.4)
#kappa_j[t,k] =  p_1[t,k]/ (1+((p_1[t,k]*N_e_sum[t-1,k])/c_1[k,1])) # Eq 4.1  - Bev holt transition estimating survival from Egg to Juvenile (plugs into Eq 4.4)
N_j[t,k] = kappa_j[t,k]*N_e_sum[t-1,k] # Eq 4.4  generated estimate for the amount of fish each year and stock that survive to a juvenile stage
kappa_marine[t,k] =  p_2[1,k]/ (1 + ((p_2[1,k]*N_j[t,k])/c_2[k,1])) # Eq 4.1   - Bev holt transition estimating survival from juvenile to spawner (plugs into Eq 4.4)
#kappa_marine[t,k] =  p_2[t,k]/ (1 + ((p_2[t,k]*N_j[t,k])/c_2[k,1])) # Eq 4.1   - Bev holt transition estimating survival from juvenile to spawner (plugs into Eq 4.4)
N_recruit[t,k] = kappa_marine[t,k]*N_j[t,k] # Eq 4.5 generated estiamte for the amount of fish each year and stock that survive to a spawning stage
# switch to track on calendar years using t+A-a
for (a in 1:A) {
N_returning[t+A-a,k,a] = N_recruit[t,k]*p[t+A-a,a]
N_sp[t+A-a,k,a] = N_returning[t+A-a,k,a] #* (1-H_b[t+A-a, k, a]) # harvest percent, 1-H_b are the ones that stay
N_e[t+A-a,k,a] = fs[a,1]*Ps*N_sp[t+A-a,k,a] #  generated estimate for the amount of eggs produced that year for that stock.
}
# transition back to brood years - plug in ages manually
N_e_sum[t,k] = (N_e[t+A-1,k,1]+N_e[t+A-2,k,2]+N_e[t+A-3,k,3]+N_e[t+A-4,k,4])
}
}
# calculate Obs Run Comp
o_run_comp = array(data = NA, dim = c(nRyrs,  A))
for (t in 1:nRyrs) {
for (a in 1:A) {
o_run_comp[t,a] = N_returning[t,1 ,a]/sum(N_returning[t,1, 1:A])
}
}
o_run_comp[nByrs:nRyrs, 1:A] <-0 # filling in NA's,they get skipped in likelihood anyway.
# try making this bigger
ess_age_comp = rep(300, times = nRyrs)
# make DFs before simulating from pop =============
N_j[1,] = mean(N_j[2:nByrs,1]) #mean(N_j[2:n,1:n.pop]) # just so i don't get yelled at about NA's later down the road
N_j_sim_hat <-  matrix(nrow=nByrs,ncol=K,NA)
N_sp_sim <-  array(data = NA, dim = c(nRyrs, K ))
N_sp_sim_s <-  array(data = NA, dim = c(nRyrs, K))
N_returning_sim <-  array(data = NA, dim = c(nRyrs, K))
N_returning_sim_s <-  array(data = NA, dim = c(nRyrs, K))
# N_return and obs age comp ============
N_returning[is.na(N_returning)] <- 0
# sum together for observation model
N_returning_sim[1:nRyrs,1]<- N_returning[1:nRyrs,1,1] + N_returning[1:nRyrs,1,2] +
N_returning[1:nRyrs,1,3] + N_returning[1:nRyrs,1,4]
N_sp[is.na(N_sp)] <- 0
N_sp_sim[1:nRyrs,1]<- N_sp[1:nRyrs,1,1] + N_sp[1:nRyrs,1,2] + N_sp[1:nRyrs,1,3] +N_sp[1:nRyrs,1,4]
for (k in 1:K) {
N_j_sim_hat[,k] = rlnorm(nByrs, log(N_j[2:nByrs,k]), process_error_j[1,1])
N_returning_sim_s[,k] = rlnorm(nRyrs, log(N_returning_sim[2:nRyrs,k]), process_error_r[1,1])
N_sp_sim_s[,k] = rlnorm(nRyrs, log(N_sp_sim[2:nRyrs,k]), process_error_sp[1,1])
}
# translate pop model to observations using the catch Q
N_j_sim_observed = N_j_sim_hat*catch_q
# population starting values supplied as data ==========
# same starting values used in simulation...
log_N_j_start =  matrix(nrow=1,ncol=K,NA)
log_N_e_sum_start = matrix(nrow=1,ncol=K,NA)
log_N_recruit_start = matrix(nrow=1,ncol=K,NA)
log_N_egg_start = array(data = NA, dim = c(A, K,A))
log_N_returning_start = array(data = NA, dim = c(A, K,A))
log_N_sp_start = array(data = NA, dim = c(A, K,A))
for(k in 1:K) {
log_N_j_start[k,1] = rnorm(1,20,2)
log_N_recruit_start[k,1] = rnorm(1,14,2)
log_N_e_sum_start[k,1] = rnorm(1,35,2)
for(t in 1:4){
for(a in 1:A){
log_N_egg_start[t,k,a] = rnorm(1,30,2)
log_N_sp_start[t,k,a] = rnorm(1,14,2)
log_N_returning_start[t,k,a] = rnorm(1,14,2)
}
}
}
## assign data list ==========
data_list <- list(nByrs=nByrs,
nRyrs=nRyrs,
A=A,
K=K,
Ps=Ps,
fs=fs,
data_stage_j = N_j_sim_observed, # after translated from "simulation" to "basis index observed" using Q multiplier.
data_stage_return = N_returning_sim_s,
data_stage_sp = N_sp_sim_s,
log_N_j_start = log_N_j_start,
log_N_recruit_start = log_N_recruit_start,
log_N_e_sum_start=log_N_e_sum_start,
log_N_egg_start=log_N_egg_start,
log_N_sp_start=log_N_sp_start,
log_N_returning_start=log_N_returning_start,
start_p_age_comp = start_p_age_comp,
sigma_y_j=process_error_j,
sigma_y_r=process_error_r,
sigma_y_sp=process_error_sp,
kappa_marine_start = matrix(p_2, nrow = 1, ncol = 1), #kappa_marine_start,
kappa_j_start = matrix(p_1,nrow = 1, ncol = 1),
# cov1 = cov1,
# cov2 = cov2,
# ncovars1 = 1,
# ncovars2 = 1,
p_1=p_1,
p_2=p_2,
log_p_1=log_p_1,
log_p_2=log_p_2,
sigma_coef1 = sigma_coef1,
sigma_coef2=sigma_coef2,
basal_p_1=basal_p_1,
basal_p_2=basal_p_2,
H_b=H_b,
#prob=prob,
pi=pi,
c_1=c_1,
c_2=c_2,
log_c_1 = log_c_1,
log_c_2=log_c_2,
D_scale = D_scale,
o_run_comp=o_run_comp,
ess_age_comp=ess_age_comp,
g = g,
p=p,
Dir_alpha=Dir_alpha)
## assign data list ==========
data_list <- list(nByrs=nByrs,
nRyrs=nRyrs,
A=A,
K=K,
Ps=Ps,
fs=fs,
data_stage_j = N_j_sim_observed, # after translated from "simulation" to "basis index observed" using Q multiplier.
data_stage_return = N_returning_sim_s,
data_stage_sp = N_sp_sim_s,
log_N_j_start = log_N_j_start,
log_N_recruit_start = log_N_recruit_start,
log_N_e_sum_start=log_N_e_sum_start,
log_N_egg_start=log_N_egg_start,
log_N_sp_start=log_N_sp_start,
log_N_returning_start=log_N_returning_start,
sigma_y_j=process_error_j,
sigma_y_r=process_error_r,
sigma_y_sp=process_error_sp,
kappa_marine_start = matrix(p_2, nrow = 1, ncol = 1), #kappa_marine_start,
kappa_j_start = matrix(p_1,nrow = 1, ncol = 1),
# cov1 = cov1,
# cov2 = cov2,
# ncovars1 = 1,
# ncovars2 = 1,
p_1=p_1,
p_2=p_2,
log_p_1=log_p_1,
log_p_2=log_p_2,
sigma_coef1 = sigma_coef1,
sigma_coef2=sigma_coef2,
basal_p_1=basal_p_1,
basal_p_2=basal_p_2,
H_b=H_b,
#prob=prob,
pi=pi,
c_1=c_1,
c_2=c_2,
log_c_1 = log_c_1,
log_c_2=log_c_2,
D_scale = D_scale,
o_run_comp=o_run_comp,
ess_age_comp=ess_age_comp,
g = g,
p=p,
Dir_alpha=Dir_alpha)
#     "D_scale"= rbeta(1,1,1))
#     # "theta1" = as.matrix(nrow = 1, ncol =1,rnorm(n=K, 0.1, 5)),
#     # "theta2" = as.matrix(nrow = 1, ncol =1,rnorm(n=K, -0.2,10)),
#     # "g"= matrix(data=rep( c(rnorm(1,40,1), rnorm(1,80,1)) , nRyrs),
#     #              nrow=nByrs, ncol=A, byrow=TRUE)
# }
#
# # Initial List of Lists for Multiple Chains
# init_ll <- lapply(1:n_chains, function(id) init_fn(chain_id = id))
# call mod  ===========================
bh_fit <- stan(
file = here::here("scripts", "stan_mod_BH_SIM.stan"), #differnt than data model so I can move priors around
data = data_list,
chains = n_chains,
warmup = warmups,
iter = total_iterations,
cores = n_cores) #init=init_ll)
write_rds(bh_fit, "output/stan_fit_SIMULATED_OUTPUT.RDS")
library(tidyverse)
library(tidybayes)
library(here)
bh_fit<- read_rds("output/stan_fit_SIMULATED_OUTPUT.RDS")
bh_summary <- summary(bh_fit)$summary %>%
as.data.frame(bh_fit) %>%
mutate(variable_mod = (names(bh_fit))) %>%
select(variable_mod, everything()) %>%
as_data_frame()
# parameters  ======================
# data_list - holds simulated values, this is from: simulate_data_age_structure.R
params<-bh_summary %>%
slice(1:5)
obs_dat <- data.frame(log_c_1  = c(data_list$log_c_1),
log_c_2 = c(data_list$log_c_2),
log_p_1 = c(data_list$log_p_1[1,1]),
log_p_2 = c(data_list$log_p_2[1,1]),
D_scale = c(data_list$D_scale)) %>%
gather(1:ncol(.), key = "variable", value = "mean_obs") %>%
cbind(params) %>%
dplyr::select(-variable_mod)
# plot ===========
obs_dat %>%
ggplot() +
geom_linerange(aes(variable, ymin = `2.5%`,ymax = `97.5%`)) +
geom_crossbar(aes(variable, mean, ymin = `25%`, ymax = `75%`), fill= 'grey') +
facet_wrap(~variable, scales = 'free') +
geom_point(aes(variable, mean_obs), color = "red" ) #observed
zoop <- read_csv(here("data", "Processed_Data", "NBS_Zoop_Process_Final.csv"))
library(here)
library(tidyverse)
zoop <- read_csv(here("data", "Processed_Data", "NBS_Zoop_Process_Final.csv"))
# Temporal trim to include month 7-10
library(here)
library(tidyverse)
zoop <- read.csv(here("data", "Processed_Data", "NBS_Zoop_Process_Final.csv"))
View(zoop)
zoop <- read.csv(here("data", "Processed_Data", "NBS_Zoop_Process_Final.csv")) %>%
group_by(DATA_SOURCE,CRUISE,HAUL_ID,YEAR,MONTH,DAY,LAT,LON, TAXON_NAME,TAXA_COARSE) %>% # sum across life stages
dplyr::summarise(EST_NUM_PERM3 =  sum(EST_NUM_PERM3)) %>%
filter(!LAT<58,
!LAT>65,
!LON> -155,
MONTH %in% c(7,8,9,10))
# Create covariate for stage 1, representing ocean entry marine diet index
# current spatial trim is just eyeballing from vast chum index that curry sent
# current latitude range that I trim zoop index too: 58-65
# Temporal trim to include month 7-10
library(here)
library(tidyverse)
zoop <- read.csv(here("data", "Processed_Data", "NBS_Zoop_Process_Final.csv")) %>%
group_by(DATA_SOURCE,CRUISE,HAUL_ID,YEAR,MONTH,DAY,LAT,LON, TAXON_NAME,TAXA_COARSE) %>% # sum across life stages
dplyr::summarise(EST_NUM_PERM3 =  sum(EST_NUM_PERM3)) %>%
filter(!LAT<58,
!LAT>65,
!LON> -155,
MONTH %in% c(7,8,9,10))
names <- data.frame(unique(zoop$TAXA_COARSE))
library(here)
library(tidyverse)
zoop <- read.csv(here("data", "Processed_Data", "NBS_Zoop_Process_Final.csv")) %>%
group_by(DATA_SOURCE,CRUISE,HAUL_ID,YEAR,MONTH,DAY,LAT,LON, TAXON_NAME,TAXA_COARSE) %>% # sum across life stages
dplyr::summarise(EST_NUM_PERM3 =  sum(EST_NUM_PERM3)) %>%
filter(!LAT<58,
!LAT>65,
!LON> -155,
MONTH %in% c(7,8,9,10))
zoop <- read.csv(here("data", "Processed_Data", "NBS_Zoop_Process_Final.csv")) %>%
group_by(DATA_SOURCE,CRUISE,HAUL_ID,YEAR,MONTH,DAY,LAT,LON, TAXON_NAME,TAXA_COARSE) %>% # sum across life stages
dplyr::summarise(EST_NUM_PERM3 =  sum(EST_NUM_PERM3)) %>%
filter(!LAT<58,
!LAT>65,
!LON> -155,
MONTH %in% c(7,8,9,10))
zoop <- read.csv("data/Processed_Data/NBS_Zoop_Process_Final.csv") %>%
group_by(DATA_SOURCE,CRUISE,HAUL_ID,YEAR,MONTH,DAY,LAT,LON, TAXON_NAME,TAXA_COARSE) %>% # sum across life stages
dplyr::summarise(EST_NUM_PERM3 =  sum(EST_NUM_PERM3)) %>%
filter(!LAT<58,
!LAT>65,
!LON> -155,
MONTH %in% c(7,8,9,10))
DF  <- read.csv(here("data", "Processed_Data", "NBS_Zoop_Process_Final.csv"))
DF  <- read.csv(here("data", "Processed_Data", "NBS_Zoop_Process_Final.csv"))
zoop <- DF %>%
group_by(DATA_SOURCE,CRUISE,HAUL_ID,YEAR,MONTH,DAY,LAT,LON, TAXON_NAME,TAXA_COARSE) %>% # sum across life stages
dplyr::summarise(EST_NUM_PERM3 =  sum(EST_NUM_PERM3)) %>%
filter(!LAT<58,
!LAT>65,
!LON> -155,
MONTH %in% c(7,8,9,10))
library(dplyr)
zoop <- DF %>%
group_by(DATA_SOURCE,CRUISE,HAUL_ID,YEAR,MONTH,DAY,LAT,LON, TAXON_NAME,TAXA_COARSE) %>% # sum across life stages
dplyr::summarise(EST_NUM_PERM3 =  sum(EST_NUM_PERM3)) %>%
filter(!LAT<58,
!LAT>65,
!LON> -155,
MONTH %in% c(7,8,9,10))
DF  <- read.csv(here("data", "Processed_Data", "NBS_Zoop_Process_Final.csv"))
zoop <- DF %>%
group_by(DATA_SOURCE,CRUISE,HAUL_ID,YEAR,MONTH,DAY,LAT,LON, TAXON_NAME,TAXA_COARSE) %>% # sum across life stages
dplyr::summarise(EST_NUM_PERM3 =  sum(EST_NUM_PERM3)) %>%
filter(!LAT<58,
!LAT>65,
!LON> -155,
MONTH %in% c(7,8,9,10))
names <- data.frame(unique(zoop$TAXA_COARSE))
# Large zoop (Themisto, calanus, large copepods) ================
large_zoop<- zoop %>%
filter(stringr::str_detect(TAXA_COARSE, paste(c( 'Themisto',
'Calanus',
'Copepod_large',
'Neocalanus'
), collapse = '|')))
# are there differences between EMA and ECOFOCI just based on plotting averages
large_zoopsumm <- large_zoop %>%
filter(!YEAR <1999) %>%
group_by(DATA_SOURCE,YEAR) %>%
dplyr::summarise(mean = mean(EST_NUM_PERM3),
n= nrow(.),
se= sd(EST_NUM_PERM3)/sqrt(n))
ggplot(data = large_zoopsumm, aes(x=YEAR, y = mean, group =DATA_SOURCE, color =DATA_SOURCE )) +
geom_point()+
geom_line() +
geom_errorbar(aes(ymin = mean-se, ymax = mean+se))
# Gelatinous Zoop - Cnideria ===============
zoop_cnideria<- zoop %>%
filter(stringr::str_detect(TAXA_COARSE, paste(c('Cnidaria_small', 'Cnidaria_large'), collapse = '|')))
zoop_cnideria_summ <- zoop_cnideria %>%
filter(!YEAR <1999) %>%
group_by(DATA_SOURCE, YEAR) %>%
dplyr::summarise(mean = mean(EST_NUM_PERM3),
n= nrow(.),
se = sd(EST_NUM_PERM3)/sqrt(n))
ggplot(data = zoop_cnideria_summ, aes(x=YEAR, y = mean, group =DATA_SOURCE, color =DATA_SOURCE )) +
geom_point()+
geom_line() +
geom_errorbar(aes(ymin = mean-se, ymax = mean+se))
library(here)
library(tidyverse)
library(readxl)
BASIS_Zoo_1999_2004 <- read_xlsx(here( "data", "Raw-Data", "EMA-Historical-Data", "BASIS_Zoo_1999_2004.xlsx"), col_types = c("text", "text", "text", "numeric", "text", "numeric", "date", "date", "date", "numeric", "numeric", "text", "numeric", "numeric", "text", "text", "numeric", "text", "numeric", "text", "text", "text", "text", "numeric", "numeric", "numeric", "text", "text", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric"))
BASIS_Zoo_2005_2009 <- read_xlsx (here("data", "Raw-Data", "EMA-Historical-Data", "BASIS_Zoo_2005_2009.xlsx"), col_types = c("text", "text", "text", "numeric", "text", "numeric", "date", "date", "date", "numeric", "numeric", "text", "numeric", "numeric", "text", "text", "numeric", "text", "numeric", "text", "text", "text", "text", "numeric", "numeric", "numeric", "text", "text", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric"))
