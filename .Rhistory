for(k in 1:K) {
log_N_j_start[k,1] = rnorm(1,20,2)
log_N_recruit_start[k,1] = rnorm(1,14,2)
log_N_e_sum_start[k,1] = rnorm(1,30,2)
for(a in 1:A){
for(t in 1:t_start){
# if(t<5){
log_N_egg_start[t,k,a] = rnorm(1,20,2)
#}
# if(t>4){
#   log_N_egg_start[t,k,a] = 0 #rnorm(1,30,2)
# }
log_N_sp_start[t,k,a] = rnorm(1,14,2)
log_N_returning_start[t,k,a] = rnorm(1,15,2)
}
}
}
## assign data list ==========
data_list <- list(nByrs=nByrs,
nRyrs=nRyrs,
A=A,
K=K,
t_start = t_start,
Ps=Ps,
fs=fs,
data_stage_j = N_j_sim_observed, # after translated from "simulation" to "basis index observed" using Q multiplier.
data_stage_return = N_returning_sim_s,
data_stage_sp = N_sp_sim_s,
log_N_j_start = log_N_j_start,
log_N_recruit_start = log_N_recruit_start,
log_N_e_sum_start=log_N_e_sum_start,
log_N_egg_start=log_N_egg_start,
log_N_sp_start=log_N_sp_start,
log_N_returning_start=log_N_returning_start,
catch_q = log(catch_q),
sigma_y_j=process_error_j,
sigma_y_r=process_error_r,
sigma_y_sp=process_error_sp,
kappa_marine_start = matrix(p_2, nrow = 1, ncol = 1), #kappa_marine_start,
kappa_j_start = matrix(p_1,nrow = 1, ncol = 1),
# cov1 = cov1,
# cov2 = cov2,
# ncovars1 = 1,
# ncovars2 = 1,
p_1=p_1,
p_2=p_2,
log_p_1=log_p_1,
log_p_2=log_p_2,
sigma_coef1 = sigma_coef1,
sigma_coef2=sigma_coef2,
basal_p_1=basal_p_1,
basal_p_2=basal_p_2,
#H_b=H_b,
#prob=prob,
pi=pi,
c_1=c_1,
c_2=c_2,
log_c_1 = log_c_1,
log_c_2=log_c_2,
D_scale = D_scale,
o_run_comp=o_run_comp,
ess_age_comp=ess_age_comp,
g = g,
p=p,
Dir_alpha=Dir_alpha)
# create initial values ===============
#
# init_fn <- function(chain_id=1) {
#   list(
#     "log_c_1" = as.matrix(nrow = 1, ncol =1,rnorm(1,18.4, 1)),
#     "log_c_2" = as.matrix(nrow = 1, ncol =1,rnorm(1,15, 1)),
#     "log_p_1" = as.matrix(nrow = 1, ncol =1,rnorm(1,-1.6, 0.5)),
#     "log_p_2" = as.matrix(nrow = 1, ncol =1,rnorm(1,-0.9, 0.5)),
#     "log_catch_q" = as.matrix(nrow = 1, ncol =1,rnorm(n=K, 0, 0.05)),
#     "D_scale"= rbeta(1,1,1))
#     # "theta1" = as.matrix(nrow = 1, ncol =1,rnorm(n=K, 0.1, 5)),
#     # "theta2" = as.matrix(nrow = 1, ncol =1,rnorm(n=K, -0.2,10)),
#     # "g"= matrix(data=rep( c(rnorm(1,40,1), rnorm(1,80,1)) , nRyrs),
#     #              nrow=nByrs, ncol=A, byrow=TRUE)
# }
#
# # Initial List of Lists for Multiple Chains
# init_ll <- lapply(1:n_chains, function(id) init_fn(chain_id = id))
# call mod  ===========================
bh_fit <- stan(
file = here::here("scripts", "stan_mod_BH_SIM.stan"), #different than data model so I can move priors around
data = data_list,
chains = n_chains,
warmup = warmups,
iter = total_iterations,
cores = n_cores) # init=init_ll)
write_rds(bh_fit, "output/stan_fit_SIMULATED_OUTPUT.RDS")
#     "D_scale"= rbeta(1,1,1))
#     # "theta1" = as.matrix(nrow = 1, ncol =1,rnorm(n=K, 0.1, 5)),
#     # "theta2" = as.matrix(nrow = 1, ncol =1,rnorm(n=K, -0.2,10)),
#     # "g"= matrix(data=rep( c(rnorm(1,40,1), rnorm(1,80,1)) , nRyrs),
#     #              nrow=nByrs, ncol=A, byrow=TRUE)
# }
#
# # Initial List of Lists for Multiple Chains
# init_ll <- lapply(1:n_chains, function(id) init_fn(chain_id = id))
# call mod  ===========================
bh_fit <- stan(
file = here::here("scripts", "stan_mod_BH_SIM.stan"), #different than data model so I can move priors around
data = data_list,
chains = n_chains,
warmup = warmups,
iter = total_iterations,
cores = n_cores) # init=init_ll)
write_rds(bh_fit, "output/stan_fit_SIMULATED_OUTPUT.RDS")
bh_summary <- summary(bh_fit)$summary %>%
as.data.frame( ) %>%
mutate(variable_mod = (names(bh_fit))) %>%
select(variable_mod, everything()) %>%
as_data_frame()
# parameters  ======================
# data_list - holds simulated values, this is from: simulate_data_age_structure.R
params<-bh_summary %>%
slice(1:4,10) %>%
separate(variable_mod, into=c("param", "delete"), sep = -5) %>%
dplyr::select(-delete) %>%
rbind(bh_summary %>%
slice(5) %>% rename(param = "variable_mod")) %>%
dplyr::mutate(mean_mod=mean) %>%
dplyr::select(param, mean_mod,`2.5%`,`25%`,`75%`,`97.5%`)
dat<-data.frame(log_c_1 = data_list$log_c_1,
log_c_2 = data_list$log_c_2,
log_catch_q = data_list$catch_q,
log_p_1 = data_list$log_p_1,
log_p_2 = data_list$log_p_2,
D_scale = data_list$D_scale#,
#g = data_list$g
) %>%
gather(1:ncol(.), key = "param", value = "mean_obs") %>%
left_join(params)
dat %>%
ggplot() +
geom_linerange(aes(param, ymin = `2.5%`,ymax = `97.5%`)) +
geom_crossbar(aes(param, mean_mod, ymin = `25%`, ymax = `75%`), fill= 'grey') +
geom_point(aes(x=param, y = mean_obs), color = "red") +
facet_wrap(~param, scales = 'free') +
labs(caption = "red is observed, black is model")
# Q ============
# compared to observed run composition in simulation and in model
obs_run_comp <- as.data.frame(colMeans(data_list$o_run_comp)) %>%
dplyr::rename(obs_run_comp = `colMeans(data_list$o_run_comp)`)
bh_summary_q <- bh_summary %>%
filter(grepl("q",variable_mod)) %>%
slice(-c(1:2)) %>%
separate(variable_mod, into = c("variable", "time", "del","age"), sep =c(-5,-3,-2,-1)) %>%
dplyr::select(-del,-variable) %>%
dplyr::mutate(variable = mean, #variable = (gsub("\\[", "", variable)),
id = "mod",
time = as.numeric((gsub("\\[", "", time)))) %>%
dplyr::select(time, id, age, variable,6,10) %>%
group_by(id, age) %>%
dplyr::summarise(mean_mod = mean(variable),
lower = mean(`2.5%`),
upper = mean(`97.5%`)) %>%
cbind(obs_run_comp)
bh_summary_q %>%
ggplot() +
geom_linerange(aes(age, ymin = lower,ymax = upper)) +
geom_point(aes(age, mean_mod ), fill= 'grey') +
geom_point(aes(age, obs_run_comp), color = "red" ) +
labs(caption = "Red is observed, black is model output") +
ggtitle("Q")
# Function to remove '[' character
remove_bracket <- function(lst) {
sapply(lst, function(x) gsub("\\[", "", x))
}
remove_comma <- function(lst) {
sapply(lst, function(x) gsub("\\,", "", x))
}
# n returning =====
# load n_returning from output and calculate proportions to see if the age structure is the same there....
proportion_q<- bh_summary %>%
filter(grepl("N_returning",variable_mod),
!grepl("start",variable_mod)) %>%
separate(variable_mod, into = c("variable", "time", "del", "age", "del1"), sep =c(11,-5,-2,-1))  %>%
dplyr::mutate(time = remove_bracket(time) ) %>%
as.data.frame() %>%
dplyr::select(-del, -del1) %>%
filter(!is.nan(mean)) %>%
group_by(time) %>%
dplyr::mutate(sum = sum(mean),
proportion = mean/sum)  %>%
select(time,age,proportion) %>%
mutate(time = as.numeric(time))
ggplot(data = proportion_q) +
geom_bar(aes(x=time, y=proportion,
fill = age, group = age), stat = "identity")
p
library(actuaryr)
library(readxl)
library(tidyverse)
library(dplyr)
library(rstan)
library(dirmult)
library(here)
library(Rlab)
#### Simulating data
# Load data for baseline ==============
warmups <- 2000
total_iterations <- 4000
max_treedepth <-  15
n_chains <- 1
n_cores <- 4
adapt_delta <- 0.95
# load salmon data ================================================
# summer_age_comp<-read_csv("data/age_comps/processed_age_comps_summer_yukon.csv")  %>%
#   filter(!cal_year < 2005 )
#
# summer_brood <- read_csv("output/yukon_summer_broodyear.csv")%>%
#   filter(!brood_year < 2002) # for now to simplify matching with juveniles
#
# yukon_summer <- read_excel("data/Yukon_Escapement_ADFG/S Chum RR 2023.xlsx", sheet = 2) %>%
#   dplyr::select(1,11:14) %>%
#   janitor::row_to_names(row_number = 1) %>%
#   dplyr::rename(cal_year = "Year")  %>%
#   dplyr::mutate(age3=as.numeric(age3),
#                 age4=as.numeric(age4),
#                 age5=as.numeric(age5),
#                 age6=as.numeric(age6)) %>%
#   filter(!cal_year < 2005)
#
# ## harvest below weir
# harvest_escapement <- read_excel("data/Yukon_Escapement_ADFG/S Chum RR 2023.xlsx", sheet = 2) %>%
#   dplyr::select(1:2,4) %>%
#   janitor::row_to_names(row_number = 1)  %>%
#   dplyr::rename(cal_year = "Year") %>%
#   dplyr::mutate(cal_year = as.numeric(cal_year),
#                 Harvest = as.numeric(Harvest),
#                 Escapement = as.numeric(Escapement)) %>%
#   filter(!cal_year < 2005) %>% # from brood year 2002 (first year of juvenile data), the first year that fish could return is 2005 if its a 3yo, the last yera it coudl return is 2007 if its a 6yo.
#   as.data.frame()  #%>%
# #as.matrix()
#
# # juv data =========
# juv<- read_csv("data/tidy_BASIS_AYK_model.csv") %>%
#   dplyr::select(1,2) %>% # yukon summer is column labeled 1, yukon fall is 2, kusko is 3
#   dplyr::rename(abund = `1`) %>%
#   filter(!brood_year>2017) #if a fish is caught in 2023 and is 6 years old,
# # then its brood  year is 2017. Need to trim so the indexing works... I think...
# Init ===================
K = 1 # number of stocks
A = 4 # age classes
nByrs= 80 #105 #number of samples per population
nRyrs = nByrs +A+1# 83 #108
t_start = A+A
pops = 1 #seq(1,3,1) #population pointer vector
population<- c(rep(1,nByrs)) #population pointer vector
#n.pop <-length(unique(population)) #number of population
#year <- rep(seq(1,n), n.pop) #creating a year pointer
Ps = 0.5 # proportion of females - assumption, need to lit check
fs = as.matrix(c(1800, 2000, 2200, 2440)) # fecundity - Gilk-Baumer 2009 estimate for Kusko Chum is: 2440. I added extra numbers temporarily just so that younger fish reproduce less, but will have to look up data for this more...
#Bev Holt parameters ===================
# p for alpha, and c for carrying capacity
basal_p_1 = 0.2
basal_p_2 = 0.4
log_c_1 = 18.4
log_c_2 = 17
c_1 <- as.matrix(nrow = 1, ncol =1, exp(log_c_1))
c_2 <- as.matrix(nrow = 1, ncol =1, exp(log_c_2))
# Covariate data ===================
cov1 <-  matrix(nrow = nByrs, ncol =1, rnorm(nByrs*1, 0, 2))  #Cov 1 data
cov2 <- matrix(nrow = nByrs, ncol =1, rnorm(nByrs*1, 0, 2))  #Cov2 data
sigma_coef1 <- as.matrix(nrow = 1, ncol =1, 0.1)
sigma_coef2 <- as.matrix(nrow = 1, ncol =1, 0.1)
mu_coef1 <- 0.1 #rnorm(0, 10)
mu_coef2 <- -0.2 #rnorm(0, 10)
theta1 <- rnorm(1,mu_coef1,sigma_coef1[1,1])
theta2 <- rnorm(1,mu_coef2,sigma_coef2[1,1])
# theta1 <- c(0.1) #rep(0.1,n), rep(0.3,n), rep(0.4,n)) #relationship for simulated data
# theta2 <- c(-0.2) #relationship for simulated data
# Make p for simulated population model =========
Dir_alpha = c(NA)
p = c(NA)#matrix(nrow=K,ncol=A,NA)
g = c(NA)#matrix(nrow=K,ncol=A,NA)
#p = matrix(nrow=nRyrs,ncol=A,NA)
#g = matrix(nrow=nRyrs,ncol=A,NA)
# prob = c(0.1148158, # rbeta(1,1,1),
#          0.2157721, # rbeta(1,1,1),
#          0.5999373)  # rbeta(1,1,1))
#D_scale =0.4 #0.01
# pi[1] = prob[1]
# pi[2] = prob[2] * (1 - pi[1])
# pi[3] = prob[3] * (1 - pi[1] - pi[2])
# pi[4] = 1 - pi[1] - pi[2] - pi[3]
# P as a parameter ========  doesnt vary through time though
#p = c(0.1148158, 0.1909981, 0.4164682, 0.2777180)
D_scale =0.3
pi = c(0.2148158, 0.1909981, 0.3164682, 0.2777180)
D_sum = 1/D_scale^2
for (a in 1:A) {
# for (t in 1:nRyrs) {
Dir_alpha[a] = D_sum * pi[a]
g[a] = rgamma(n=1,Dir_alpha[a],1)
#     g[t,a] = rgamma(n=1,Dir_alpha[a],1)
#  }
}
for (a in 1:A) {
#  for (t in 1:nRyrs) {
p[a] = g[a]/sum(g[1:A])
# }
}
# Process error  ===================
# error is fixed in model right now so fix it here.
process_error_j <- matrix(nrow=K,ncol=1,rep(1, times =K))  #matrix(nrow=nByrs,ncol=1,rep(1, times =nByrs )) #rnorm(nByrs*1,1,0.2))
process_error_sp <- matrix(nrow=K,ncol=1,rep(1, times =K)) #matrix(nrow=nRyrs,ncol=1,rep(2, times =nRyrs )) #rnorm(nByrs*1,5, 1))
process_error_r <- matrix(nrow=K,ncol=1,rep(1, times =K))  #matrix(nrow=nRyrs,ncol=1,rep(3, times =nRyrs )) #rnorm(nByrs*1,5, 1))
# make pop model matricies and starting values =========
kappa_j =  matrix(nrow=nByrs,ncol=K,NA)
kappa_marine =  matrix(nrow=nByrs,ncol=K,NA)
N_j =  matrix(nrow=nByrs,ncol=K,NA)
N_e_sum = matrix(nrow=nByrs,ncol=K,NA)
N_e = array(data = NA, dim = c(nRyrs, K,A))
N_recruit = matrix(nrow=nRyrs,ncol=K,NA)
N_returning = array(data = NA, dim = c(nRyrs, K,A))
N_returning_test = array(data = NA, dim = c(nRyrs, K,A)) # new
N_sp = array(data = NA, dim = c(nRyrs, K,A))
## starting values ========
N_j[1,1] = exp(rnorm(1,20,2)) #mean(juv$abund)# rnorm(K,20,10)
N_recruit[1,1] = exp(rnorm(1,14,2)) #mean(harvest_escapement$Harvest)
for(t in 1:4){
N_e[t,1,] = exp(rnorm(A,20,2))
}
for(t in 4:8){
N_e[t,1,] = 0 #exp(rnorm(A,20,2))
}
for(t in 1:4){
N_sp[t,1,]  = rep(exp(rnorm(1,14,2))*p, times =1)
N_returning[t,1,]  = rep(exp(rnorm(1,15,2))*p, times =1)
}
N_e_sum[1,1] = exp(rnorm(1,30,2))
# productivity =============
# p_1 =  matrix(nrow=nByrs,ncol=K,NA)
# p_2 =  matrix(nrow=nByrs,ncol=K,NA)
log_p_1 =  matrix(nrow=1,ncol=K,-0.5) #rnorm(1,-1, 0.5))
log_p_2 =  matrix(nrow=1,ncol=K,0.02) #rnorm(1,-0.5, 0.5))
p_1 = exp(log_p_1)
p_2 = exp(log_p_2)
catch_q = 0.7 #exp(rnorm(1,0,0.5))
log_catch_q= log(catch_q)
# Use covariates - calculate productivity in bev holt transition function =====
# lines below need to be edited if I use more stocks!! theta and cov 1 should be multipled and summed, can get away with just multiplying here because there is only 1 stock and 1 covar
# save for when I try to run with covariates
# p_1[,1]  = 1 / 1+ exp(-basal_p_1 - (theta1*cov1[,1])) # covariate impacts survival, impact is measured through theta
# p_2[,1]  = 1 / 1+ exp(-basal_p_2  - (theta2 *cov2[,1]))
# Harvest H_b ==========
# this is the harvest, going to do a percent of the population instead of whole numbers
# simulating with dirichlet leads to age structure being the same across all ages at 0.25
##H_b  <-  array(data = rdirichlet(n=nRyrs, alpha=rep(10,A)), dim = c(nRyrs, K, A)) # higher value for alpha is a more tightly clustered distribution
#H_b  <-  array(data = rdirichlet(n=nRyrs, alpha=rep(10,A)), dim = c(nRyrs, K, A)) # higher value for alpha is a more tightly clustered distribution
##H_b  <-  array(data = rmultinom(n=nRyrs,size =500, prob = pi),
#               dim = c(nRyrs, K, A))
#### Simulating data
# Load data for baseline ==============
warmups <- 2000
total_iterations <- 4000
max_treedepth <-  15
n_chains <- 1
n_cores <- 4
adapt_delta <- 0.95
# load salmon data ================================================
# summer_age_comp<-read_csv("data/age_comps/processed_age_comps_summer_yukon.csv")  %>%
#   filter(!cal_year < 2005 )
#
# summer_brood <- read_csv("output/yukon_summer_broodyear.csv")%>%
#   filter(!brood_year < 2002) # for now to simplify matching with juveniles
#
# yukon_summer <- read_excel("data/Yukon_Escapement_ADFG/S Chum RR 2023.xlsx", sheet = 2) %>%
#   dplyr::select(1,11:14) %>%
#   janitor::row_to_names(row_number = 1) %>%
#   dplyr::rename(cal_year = "Year")  %>%
#   dplyr::mutate(age3=as.numeric(age3),
#                 age4=as.numeric(age4),
#                 age5=as.numeric(age5),
#                 age6=as.numeric(age6)) %>%
#   filter(!cal_year < 2005)
#
# ## harvest below weir
# harvest_escapement <- read_excel("data/Yukon_Escapement_ADFG/S Chum RR 2023.xlsx", sheet = 2) %>%
#   dplyr::select(1:2,4) %>%
#   janitor::row_to_names(row_number = 1)  %>%
#   dplyr::rename(cal_year = "Year") %>%
#   dplyr::mutate(cal_year = as.numeric(cal_year),
#                 Harvest = as.numeric(Harvest),
#                 Escapement = as.numeric(Escapement)) %>%
#   filter(!cal_year < 2005) %>% # from brood year 2002 (first year of juvenile data), the first year that fish could return is 2005 if its a 3yo, the last yera it coudl return is 2007 if its a 6yo.
#   as.data.frame()  #%>%
# #as.matrix()
#
# # juv data =========
# juv<- read_csv("data/tidy_BASIS_AYK_model.csv") %>%
#   dplyr::select(1,2) %>% # yukon summer is column labeled 1, yukon fall is 2, kusko is 3
#   dplyr::rename(abund = `1`) %>%
#   filter(!brood_year>2017) #if a fish is caught in 2023 and is 6 years old,
# # then its brood  year is 2017. Need to trim so the indexing works... I think...
# Init ===================
K = 1 # number of stocks
A = 4 # age classes
nByrs= 80 #105 #number of samples per population
nRyrs = nByrs +A+1# 83 #108
t_start = A+A
pops = 1 #seq(1,3,1) #population pointer vector
population<- c(rep(1,nByrs)) #population pointer vector
#n.pop <-length(unique(population)) #number of population
#year <- rep(seq(1,n), n.pop) #creating a year pointer
Ps = 0.5 # proportion of females - assumption, need to lit check
fs = as.matrix(c(1800, 2000, 2200, 2440)) # fecundity - Gilk-Baumer 2009 estimate for Kusko Chum is: 2440. I added extra numbers temporarily just so that younger fish reproduce less, but will have to look up data for this more...
#Bev Holt parameters ===================
# p for alpha, and c for carrying capacity
basal_p_1 = 0.2
basal_p_2 = 0.4
log_c_1 = 18.4
log_c_2 = 17
c_1 <- as.matrix(nrow = 1, ncol =1, exp(log_c_1))
c_2 <- as.matrix(nrow = 1, ncol =1, exp(log_c_2))
# Covariate data ===================
cov1 <-  matrix(nrow = nByrs, ncol =1, rnorm(nByrs*1, 0, 2))  #Cov 1 data
cov2 <- matrix(nrow = nByrs, ncol =1, rnorm(nByrs*1, 0, 2))  #Cov2 data
sigma_coef1 <- as.matrix(nrow = 1, ncol =1, 0.1)
sigma_coef2 <- as.matrix(nrow = 1, ncol =1, 0.1)
mu_coef1 <- 0.1 #rnorm(0, 10)
mu_coef2 <- -0.2 #rnorm(0, 10)
theta1 <- rnorm(1,mu_coef1,sigma_coef1[1,1])
theta2 <- rnorm(1,mu_coef2,sigma_coef2[1,1])
# theta1 <- c(0.1) #rep(0.1,n), rep(0.3,n), rep(0.4,n)) #relationship for simulated data
# theta2 <- c(-0.2) #relationship for simulated data
# Make p for simulated population model =========
Dir_alpha = c(NA)
p = c(NA)#matrix(nrow=K,ncol=A,NA)
g = c(NA)#matrix(nrow=K,ncol=A,NA)
#p = matrix(nrow=nRyrs,ncol=A,NA)
#g = matrix(nrow=nRyrs,ncol=A,NA)
# prob = c(0.1148158, # rbeta(1,1,1),
#          0.2157721, # rbeta(1,1,1),
#          0.5999373)  # rbeta(1,1,1))
#D_scale =0.4 #0.01
# pi[1] = prob[1]
# pi[2] = prob[2] * (1 - pi[1])
# pi[3] = prob[3] * (1 - pi[1] - pi[2])
# pi[4] = 1 - pi[1] - pi[2] - pi[3]
# P as a parameter ========  doesnt vary through time though
#p = c(0.1148158, 0.1909981, 0.4164682, 0.2777180)
D_scale =0.3
pi = c(0.2148158, 0.1909981, 0.3164682, 0.2777180)
D_sum = 1/D_scale^2
for (a in 1:A) {
# for (t in 1:nRyrs) {
Dir_alpha[a] = D_sum * pi[a]
g[a] = rgamma(n=1,Dir_alpha[a],1)
#     g[t,a] = rgamma(n=1,Dir_alpha[a],1)
#  }
}
for (a in 1:A) {
#  for (t in 1:nRyrs) {
p[a] = g[a]/sum(g[1:A])
# }
}
# Process error  ===================
# error is fixed in model right now so fix it here.
process_error_j <- matrix(nrow=K,ncol=1,rep(1, times =K))  #matrix(nrow=nByrs,ncol=1,rep(1, times =nByrs )) #rnorm(nByrs*1,1,0.2))
process_error_sp <- matrix(nrow=K,ncol=1,rep(1, times =K)) #matrix(nrow=nRyrs,ncol=1,rep(2, times =nRyrs )) #rnorm(nByrs*1,5, 1))
process_error_r <- matrix(nrow=K,ncol=1,rep(1, times =K))  #matrix(nrow=nRyrs,ncol=1,rep(3, times =nRyrs )) #rnorm(nByrs*1,5, 1))
# make pop model matricies and starting values =========
kappa_j =  matrix(nrow=nByrs,ncol=K,NA)
kappa_marine =  matrix(nrow=nByrs,ncol=K,NA)
N_j =  matrix(nrow=nByrs,ncol=K,NA)
N_e_sum = matrix(nrow=nByrs,ncol=K,NA)
N_e = array(data = NA, dim = c(nRyrs, K,A))
N_recruit = matrix(nrow=nRyrs,ncol=K,NA)
N_returning = array(data = NA, dim = c(nRyrs, K,A))
N_returning_test = array(data = NA, dim = c(nRyrs, K,A)) # new
N_sp = array(data = NA, dim = c(nRyrs, K,A))
## starting values ========
N_j[1,1] = exp(rnorm(1,20,2)) #mean(juv$abund)# rnorm(K,20,10)
N_recruit[1,1] = exp(rnorm(1,14,2)) #mean(harvest_escapement$Harvest)
for(t in 1:4){
N_e[t,1,] = exp(rnorm(A,20,2))
}
for(t in 4:8){
N_e[t,1,] = 0 #exp(rnorm(A,20,2))
}
for(t in 1:4){
N_sp[t,1,]  = rep(exp(rnorm(1,14,2))*p, times =1)
N_returning[t,1,]  = rep(exp(rnorm(1,15,2))*p, times =1)
}
N_e_sum[1,1] = exp(rnorm(1,30,2))
# productivity =============
# p_1 =  matrix(nrow=nByrs,ncol=K,NA)
# p_2 =  matrix(nrow=nByrs,ncol=K,NA)
log_p_1 =  matrix(nrow=1,ncol=K,-0.5) #rnorm(1,-1, 0.5))
log_p_2 =  matrix(nrow=1,ncol=K,0.02) #rnorm(1,-0.5, 0.5))
p_1 = exp(log_p_1)
p_2 = exp(log_p_2)
catch_q = 0.7 #exp(rnorm(1,0,0.5))
log_catch_q= log(catch_q)
# Use covariates - calculate productivity in bev holt transition function =====
# lines below need to be edited if I use more stocks!! theta and cov 1 should be multipled and summed, can get away with just multiplying here because there is only 1 stock and 1 covar
# save for when I try to run with covariates
# p_1[,1]  = 1 / 1+ exp(-basal_p_1 - (theta1*cov1[,1])) # covariate impacts survival, impact is measured through theta
# p_2[,1]  = 1 / 1+ exp(-basal_p_2  - (theta2 *cov2[,1]))
# Harvest H_b ==========
# this is the harvest, going to do a percent of the population instead of whole numbers
# simulating with dirichlet leads to age structure being the same across all ages at 0.25
##H_b  <-  array(data = rdirichlet(n=nRyrs, alpha=rep(10,A)), dim = c(nRyrs, K, A)) # higher value for alpha is a more tightly clustered distribution
#H_b  <-  array(data = rdirichlet(n=nRyrs, alpha=rep(10,A)), dim = c(nRyrs, K, A)) # higher value for alpha is a more tightly clustered distribution
##H_b  <-  array(data = rmultinom(n=nRyrs,size =500, prob = pi),
#               dim = c(nRyrs, K, A))
N_returning
